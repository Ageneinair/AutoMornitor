{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2                                # state of the art computer vision algorithms library\n",
    "# import numpy as np                        # fundamental package for scientific computing\n",
    "# import matplotlib.pyplot as plt           # 2D plotting library producing publication quality figures\n",
    "# from pyntcloud import PyntCloud # open source library for 3D pointcloud visualisation\n",
    "# import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API\n",
    "# print(\"Environment Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup:\n",
    "# pipe = rs.pipeline()\n",
    "# cfg = rs.config()\n",
    "# cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "# cfg.enable_stream(rs.stream.color, 640, 480, rs.format.rgb8, 30)\n",
    "    \n",
    "# profile = pipe.start(cfg)\n",
    "\n",
    "# # Skip 5 first frames to give the Auto-Exposure time to adjust\n",
    "# for x in range(5):\n",
    "#   pipe.wait_for_frames()\n",
    "  \n",
    "# # Store next frameset for later processing:\n",
    "# frameset = pipe.wait_for_frames()\n",
    "# color_frame = frameset.get_color_frame()\n",
    "# depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "# # Cleanup:\n",
    "# pipe.stop()\n",
    "# print(\"Frames Captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color = np.asanyarray(color_frame.get_data())\n",
    "# plt.rcParams[\"axes.grid\"] = False\n",
    "# plt.imshow(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(color_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc = rs.pointcloud()\n",
    "# pc.map_to(color_frame)\n",
    "# pointcloud = pc.calculate(depth_frame)\n",
    "# vtx = np.asarray(pointcloud.get_vertices())\n",
    "# pointcloud.export_to_ply(\"1.ply\", color_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a ply point cloud, print it, and render it\n"
     ]
    }
   ],
   "source": [
    "# examples/Python/Basic/visualization.py\n",
    "\n",
    "import numpy as np\n",
    "from open3d import *\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Load a ply point cloud, print it, and render it\")\n",
    "    pcd = read_point_cloud(\"1.ply\")\n",
    "    draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrealsense2.pyrealsense2.points object at 0x7ffae83ad4c8>\n",
      "Saving to 1.ply...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "\n",
    "\n",
    "# Declare pointcloud object, for calculating pointclouds and texture mappings\n",
    "pc = rs.pointcloud()\n",
    "# We want the points object to be persistent so we can display the last cloud when a frame drops\n",
    "points = rs.points()\n",
    "\n",
    "# Declare RealSense pipeline, encapsulating the actual device and sensors\n",
    "pipe = rs.pipeline()\n",
    "#Start streaming with default recommended configuration\n",
    "pipe.start();\n",
    "\n",
    "try:\n",
    "    # Wait for the next set of frames from the camera\n",
    "    frames = pipe.wait_for_frames()\n",
    "\n",
    "    # Fetch color and depth frames\n",
    "    depth = frames.get_depth_frame()\n",
    "    color = frames.get_color_frame()\n",
    "\n",
    "    # Tell pointcloud object to map to this color frame\n",
    "    pc.map_to(color)\n",
    "\n",
    "    # Generate the pointcloud and texture mappings\n",
    "    points = pc.calculate(depth)\n",
    "    \n",
    "    print(points)\n",
    "    \n",
    "\n",
    "    print(\"Saving to 1.ply...\")\n",
    "    points.export_to_ply(\"1.ply\", color)\n",
    "    print(\"Done\")\n",
    "finally:\n",
    "    pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'as_depth_frame',\n",
       " 'as_frame',\n",
       " 'as_frameset',\n",
       " 'as_motion_frame',\n",
       " 'as_points',\n",
       " 'as_pose_frame',\n",
       " 'as_video_frame',\n",
       " 'data',\n",
       " 'export_to_ply',\n",
       " 'frame_number',\n",
       " 'frame_timestamp_domain',\n",
       " 'get_data',\n",
       " 'get_frame_metadata',\n",
       " 'get_frame_number',\n",
       " 'get_frame_timestamp_domain',\n",
       " 'get_profile',\n",
       " 'get_texture_coordinates',\n",
       " 'get_timestamp',\n",
       " 'get_vertices',\n",
       " 'is_depth_frame',\n",
       " 'is_frame',\n",
       " 'is_frameset',\n",
       " 'is_motion_frame',\n",
       " 'is_points',\n",
       " 'is_pose_frame',\n",
       " 'is_video_frame',\n",
       " 'keep',\n",
       " 'profile',\n",
       " 'size',\n",
       " 'supports_frame_metadata',\n",
       " 'swap',\n",
       " 'timestamp']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrealsense2.pyrealsense2.BufData object at 0x7ffae80b9b90>\n"
     ]
    }
   ],
   "source": [
    "print(color.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
